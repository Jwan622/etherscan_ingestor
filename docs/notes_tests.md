# Notes about tests

Damn you pytest. Standard gotchas again... imports driving you insane and mocking things (you can mock variables it turns out in a module which makes mocking the config and .env so much easier.)

I tested the database with a fake test database and then also tested it by just testing the messages sent to the API. Depending on what philosphy you guys have, can do either one.

## Fixtures


### How do fixtures work?
From the pytest docs:
https://docs.pytest.org/en/6.2.x/fixture.html#requesting-fixtures

> When pytest goes to run a test, it looks at the parameters in that test functionâ€™s signature, and then searches for fixtures that have the same names as those parameters. Once pytest finds them, it runs those fixtures, captures what they returned (if anything), and passes those objects into the test function as arguments.

How does it do this?

My answer: probably using `dir()` and `inspect` on the module.

1. Fixture Registration
When pytest starts, it scans all available Python files in the directory for tests and fixtures. During this discovery phase, pytest registers fixtures defined in the code. Fixtures are usually defined using the @pytest.fixture decorator, which makes them recognizable to pytest.

2. Collecting Tests and Dependency Resolution
Pytest collects all the test functions and classes in the specified test files. For each test function, pytest analyzes the parameters required by the function. It then performs a dependency resolution by matching these parameters with the registered fixtures based on their names. This process determines the order in which fixtures need to be executed. The dependencies between fixtures (where one fixture uses another) also factor into this resolution, establishing a hierarchy or a graph of fixture dependencies.

3. Fixture Execution Order
Based on the dependency graph, pytest determines the order in which fixtures should be run. If Fixture B depends on Fixture A, pytest ensures that Fixture A runs before Fixture B. This order is critical to ensure that each fixture has the necessary environment or data setup by its dependent fixtures.


### Scoped fixtures

Fixtures requiring network access depend on connectivity and are usually time-expensive to create. Extending the previous example, we can add a scope="module" parameter to the @pytest.fixture invocation to cause a smtp_connection fixture function, responsible to create a connection to a preexisting SMTP server, to only be invoked once per test module (the default is to invoke once per test function). Multiple test functions in a test module will thus each receive the same smtp_connection fixture instance, thus saving time. Possible values for scope are: function, class, module, package or session.

The next example puts the fixture function into a separate conftest.py file so that tests from multiple test modules in the directory can access the fixture function:

```python3
# content of conftest.py
import pytest
import smtplib


@pytest.fixture(scope="module")
def smtp_connection():
    return smtplib.SMTP("smtp.gmail.com", 587, timeout=5)

```


## Testing context managers

lol this took me forever to figure out how stub out the context manager's return_value

```python3
mock_executor.return_value.__enter__.return_value.submit = mock_submit
```

That's able to stub out:

```python3
with ThreadPoolExecutor(max_workers=THREADS_COUNT) as executor:
    print('executor: ', executor)
    futures = []
    for i in range(THREADS_COUNT):
        thread_start_block = starting_block + i * blocks_per_thread
        thread_end_block = thread_start_block + blocks_per_thread - 1
        if i == THREADS_COUNT - 1:  # Ensure the last thread covers all remaining blocks
            thread_end_block = ending_block

        futures.append(executor.submit(ingest, DEFAULT_ADDRESS, thread_start_block, thread_end_block, i))
```


### Testing Philosophy

You can test messages sent to the api OR test a test database. I think the latter is better and more stable for refactors. I like using a test database because that's going to be more stable (will keep passing) under refactors whereas messages sent to apis and the order may be more brittle of a test (false negative).

